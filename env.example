# LLM integration config
OPENAI_API_URL=
OPENAI_API_KEY=
OPENAI_API_TIMEOUT=1200
MODEL=gpt-5
MAX_PROMPT_OUTPUT=
REASONING_EFFORT=low

# IDE integration
IDE_MCP_HOST=http://127.0.0.1:63342/
HTTP_PORT=5000

# File operation mode for agents
# Options: "mcp" (use external MCP server) | "pure" (direct filesystem access)
# Default: "mcp"
# - "mcp": Use IDE's MCP server for file operations (requires IDE_MCP_HOST)
# - "pure": Use direct Python file I/O (no MCP server needed, useful for testing)
AGENT_FILE_TOOLS=mcp

# Agent settings
MAX_ITERATION=20

# Debug settings
DEBUG=0

# Experimental features
# DEEPTHINKING_AGENTS=ANALYTIC,CODER